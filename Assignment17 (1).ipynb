{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n\nWeb Scraping is the process of automatically extracting data from websites. It involves fetching web pages and parsing their content to retrieve useful information.\n\nUse Cases:\nData collection: Extracting structured data from websites for analysis or research.\nCompetitive analysis: Monitoring competitors' pricing, product offerings, or reviews.\n\nThree Areas Where Web Scraping is Used to Get Data:\nE-commerce Price Monitoring: It is used to collect product prices, descriptions, and availability from e-commerce websites like Amazon, eBaye etc. This data is often used for price comparison or to track price changes over time.\nFinancial Data Extraction: Scraping websites like stock exchanges, financial news sites, or company reports is common in the finance industry. It helps to track stock prices, analyze market trends, and gather real-time financial data.\nJob Listings: Web scraping is often used to extract job postings from sites like LinkedIn, Indeed, or Glassdoor. The extracted data can be used to create a job search engine, track employment trends, or analyze salary data across different industries and regions.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q2. What are the different methods used for Web Scraping?\n\nAre:\nManual Scraping This is the simplest method where a user manually copies data from web pages.\nUsing Web Scraping Libraries/Frameworks: Programming libraries and frameworks are used to automate the process of extracting data from websites. These methods \n                                         require coding skills, typically in Python, to use the libraries for scraping.\n\n                                                                                                                                                                                    \nAPI Scraping: When a website provides an API, data can be directly fetched in a structured format (e.g., JSON, XML) without scraping the website itself. \n              Many websites offer public APIs, which are an efficient alternative to web scraping.\n\nXPath and CSS Selectors: XPath and CSS selectors are query languages used to locate and select elements in an HTML document.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q3. What is Beautiful Soup? Why is it used?\n\nBeautifulSoup is a Python library used for parsing HTML and XML documents. It creates parse trees from page source code that can be used to extract data from web pages.\nUsed: Web Scraping, HTML/XML Parsing, Data Extraction.                                                                                             ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q4. Why is flask used in this Web Scraping project?\n\nFlask is a lightweight Python web framework used to build web applications. In the context of a web scraping project, Flask can be employed to create a simple \nweb interface or API to expose the scraped data to users or other applications.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\nAre:\nAmazon EC2 (Elastic Compute Cloud): Amazon EC2 provides resizable compute capacity in the cloud. It is essentially a virtual server that we can use to run our \n                                    web scraping script or web application.\n\nAmazon S3 (Simple Storage Service): Amazon S3 is an object storage service that offers highly scalable, durable, and low-latency storage. It can be used to store \n                                    the results of our web scraping, such as CSV files, JSON data, or images.\n\n\nAWS Lambda: AWS Lambda is a serverless computing service that allows us to run code in response to events (such as changes in data or time intervals) \n            without provisioning or managing servers.\n\n\n    \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}